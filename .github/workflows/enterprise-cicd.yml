name: Enterprise CI/CD

on:
  workflow_dispatch:
    inputs:
      track:
        description: "Deployment track"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - stg
  push:
    # Intentionally *not* main: avoid accidentally deploying whatever is on main until branches are in place.
    branches:
      - dev
      - stg

permissions:
  contents: read
  actions: write

concurrency:
  group: enterprise-cicd-${{ github.event_name == 'workflow_dispatch' && inputs.track || github.ref_name }}
  cancel-in-progress: true

env:
  AWS_REGION: us-east-1
  AWS_DEFAULT_REGION: us-east-1
  ASSETS_ROOT: assets
  CARGO_TARGET_DIR: ${{ github.workspace }}/target

jobs:
  runner_check:
    name: Check mud self-hosted runner availability
    runs-on: ubuntu-latest
    outputs:
      runner_name: ${{ steps.find_runner.outputs.runner_name }}
      runner_count: ${{ steps.find_runner.outputs.runner_count }}

    steps:
      - name: Find available mud runner
        id: find_runner
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          if ! runner_snapshot="$(
            gh api repos/${{ github.repository }}/actions/runners --paginate \
              --jq '.runners | map({name: .name, status: .status, busy: .busy, labels: (.labels | map(.name)})'
          )"; then
            echo "::warning::Runner inventory check is unavailable for the CI token; continuing without hard fail."
            echo "runner_name=unknown" >> "$GITHUB_OUTPUT"
            echo "runner_count=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          runner_names="$(
            printf "%s" "$runner_snapshot" | jq -r '
              map(
                select(
                  .status=="online" and
                  (.labels | index("self-hosted")) != null and
                  (.labels | index("Linux")) != null and
                  (.labels | index("mud")) != null
                )
              )
              | map(.name)
              | sort
              | unique
              | join(",")
            '
          )"
          runner_count="$(printf "%s" "$runner_names" | awk -F',' '{print (NF==1 && $1=="" ? 0 : NF)}')"

          if [ "$runner_count" -eq 0 ]; then
            echo "::error::No online self-hosted runner matching labels [self-hosted, Linux, mud] was found."
            echo "Registered runners:"
            printf "%s" "$runner_snapshot" | jq -r 'map("\(.name): status=\(.status) busy=\(.busy) labels=\(.labels | join(\",\"))") | join("\n")'
            exit 1
          fi

          echo "runner_name=$runner_names" >> "$GITHUB_OUTPUT"
          echo "runner_count=$runner_count" >> "$GITHUB_OUTPUT"
          echo "::notice::Using mud runner(s): $runner_names"

  build:
    name: Build + Store Asset
    needs: runner_check
    if: fromJSON(needs.runner_check.outputs.runner_count) > 0
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 60

    outputs:
      track: ${{ steps.meta.outputs.track }}
      deploy_env: ${{ steps.meta.outputs.deploy_env }}
      sha: ${{ steps.meta.outputs.sha }}
      artifact_path: ${{ steps.meta.outputs.artifact_path }}
      bucket: ${{ steps.s3.outputs.bucket }}
      key: ${{ steps.s3.outputs.key }}
      e2e_core: ${{ steps.scope.outputs.run_e2e_core }}
      e2e_ws: ${{ steps.scope.outputs.run_e2e_ws }}
      e2e_scope_reason: ${{ steps.scope.outputs.scope_reason }}
      e2e_scope_count: ${{ steps.scope.outputs.changed_count }}
      e2e_scope_files: ${{ steps.scope.outputs.changed_files }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # Keep build output/cargo target dirs on the runner for speed.
          fetch-depth: 2
          clean: false

      - name: Meta
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          sha="${GITHUB_SHA}"
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            track="${{ inputs.track }}"
          else
            track="${GITHUB_REF_NAME}"
          fi

          echo "sha=$sha" >> "$GITHUB_OUTPUT"
          echo "track=$track" >> "$GITHUB_OUTPUT"

          case "$track" in
            dev) deploy_env="dev" ;;
            stg) deploy_env="stg" ;;
            *) echo "unknown track: $track" >&2; exit 2 ;;
          esac
          echo "deploy_env=$deploy_env" >> "$GITHUB_OUTPUT"

      - name: Preflight disk hygiene
        shell: bash
        run: |
          set -euo pipefail
          echo "Disk before cleanup"
          df -h /

          if [[ "${GITHUB_REF_NAME}" == "dev" ]]; then
            echo "Dev branch: keeping workspace and target caches for warm builds."
          else
            avail_kb="$(df -Pk / | awk 'NR==2 {print $4}')"
            if [ "${avail_kb}" -lt 1572864 ]; then
              echo "Disk pressure detected; pruning local target caches to preserve stability."
              rm -rf "$GITHUB_WORKSPACE/target"
              rm -rf /opt/actions-runner/_work/slopmud/slopmud/target
            else
              echo "Keeping local cargo target directories for warm-cache compile speed."
            fi
          fi
          find /opt/actions-runner/_diag -type f -name '*.log' -mtime +7 -delete || true

          avail_kb="$(df -Pk / | awk 'NR==2 {print $4}')"
          if [ "${avail_kb}" -lt 1048576 ]; then
            echo "insufficient free space on / (available ${avail_kb} KB)" >&2
            echo "manual cleanup required on the runner host before retrying" >&2
            exit 2
          fi

          echo "Disk after cleanup"
          df -h /

      - name: Assert Runner Build Deps
        shell: bash
        run: |
          set -euo pipefail
          for c in gcc make pkg-config just python3 tar; do
            command -v "$c" >/dev/null 2>&1 || {
              echo "missing build dependency: $c" >&2
              echo "bootstrap the runner once (as admin on the host) using scripts/cicd/bootstrap_runner.sh" >&2
              exit 2
            }
          done

          # Only required for the S3 artifact path; dev track can fall back to local artifacts.
          command -v aws >/dev/null 2>&1 || {
            echo "WARN: aws CLI is missing; S3 upload will fail (dev continues, stg/prod requires aws)" >&2
          }

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version
          rustc --version

      - name: Scope E2E Targets
        id: scope
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/ci_scope_e2e.sh

      - name: Restore Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Validate (fast + strict)
        id: validate
        shell: bash
        env:
          RUSTFLAGS: "-D warnings"
          DEPLOY_ENV: ${{ steps.meta.outputs.deploy_env }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          just fmt-check
          just py-check

          # dev: keep this fast for iteration; stg: run the full validation suite.
          if [[ "$DEPLOY_ENV" == "dev" ]]; then
            cargo test -p slopmud --no-run
          else
            cargo build --workspace --all-targets
            cargo test
            just world-validate
            just proto-lint
          fi
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::validate_duration_s=${duration_s}"
          echo "duration_s=${duration_s}" >> "$GITHUB_OUTPUT"

      - name: Build Asset (non-cleanroom)
        id: build_asset
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          # Clean rebuild only on the stg branch/track.
          CLEAN_BUILD: ${{ steps.meta.outputs.deploy_env == 'stg' && '1' || '0' }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          artifact_path="$(./scripts/cicd/build_assets.sh)"
          echo "artifact_path=$artifact_path" >> "$GITHUB_OUTPUT"
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::build_asset_duration_s=${duration_s}"
          echo "duration_s=${duration_s}" >> "$GITHUB_OUTPUT"

      - name: Upload To S3
        id: s3
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          SHA: ${{ steps.meta.outputs.sha }}
          ARTIFACT_PATH: ${{ steps.build_asset.outputs.artifact_path }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          account_id="$(aws sts get-caller-identity --query Account --output text)"
          bucket="slopmud-assets-${account_id}-${AWS_REGION}"
          key="${TRACK}/${SHA}/artifact.tgz"

          set +e
          aws s3 cp "$ARTIFACT_PATH" "s3://${bucket}/${key}"
          rc=$?
          set -e
          if [[ $rc -ne 0 ]]; then
            if [[ "$TRACK" == "dev" ]]; then
              echo "WARN: S3 upload failed (dev track continues without S3). Apply terraform to create/permit the assets bucket." >&2
              bucket=""
              key=""
            else
              exit $rc
            fi
          fi

          echo "bucket=$bucket" >> "$GITHUB_OUTPUT"
          echo "key=$key" >> "$GITHUB_OUTPUT"
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::s3_upload_duration_s=${duration_s}"
          echo "duration_s=${duration_s}" >> "$GITHUB_OUTPUT"

  deploy_sandbox:
    name: Deploy to sandbox (pre-dev smoke)
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 20
    needs: build
    if: needs.build.outputs.deploy_env == 'dev'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Deploy to sandbox
        id: deploy
        shell: bash
        env:
          ARTIFACT_PATH: ${{ needs.build.outputs.artifact_path }}
          BUCKET: ${{ needs.build.outputs.bucket }}
          KEY: ${{ needs.build.outputs.key }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"

          if [[ -n "${BUCKET}" && -n "${KEY}" ]]; then
            ./scripts/cicd/slopmud-shuttle-assets \
              --env sandbox \
              --from-s3 "s3://${BUCKET}/${KEY}"
          else
            ./scripts/cicd/slopmud-shuttle-assets \
              --env sandbox \
              --from-file "$ARTIFACT_PATH"
          fi
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::sandbox_deploy_duration_s=${duration_s}"
          echo "duration_s=${duration_s}" >> "$GITHUB_OUTPUT"

      - name: Smoke Test
        id: smoke
        shell: bash
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4500
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::sandbox_smoke_duration_s=${duration_s}"

  e2e-core-local:
    name: E2E (core local, fast)
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 25
    needs: [build, deploy_sandbox]
    if: >
      needs.build.outputs.deploy_env == 'dev' &&
      needs.build.outputs.e2e_core == '1'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version

      - name: Restore Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Run e2e-local (skip-build)
        id: run
        shell: bash
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          python3 scripts/e2e_local.py --skip-build
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::e2e_local_duration_s=${duration_s}"

  e2e-core-party:
    name: E2E (core party, fast)
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 25
    needs: [build, deploy_sandbox]
    if: >
      needs.build.outputs.deploy_env == 'dev' &&
      needs.build.outputs.e2e_core == '1'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version

      - name: Restore Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Run e2e-party (skip-build)
        id: run
        shell: bash
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          python3 scripts/e2e_party_run.py --skip-build
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::e2e_party_duration_s=${duration_s}"

  e2e-ws:
    name: E2E (ws gateway)
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 25
    needs: [build, deploy_sandbox]
    if: >
      needs.build.outputs.deploy_env == 'dev' &&
      needs.build.outputs.e2e_ws == '1'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version

      - name: Restore Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Build and run ws e2e
        id: run
        shell: bash
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          cargo build -q -p ws_gateway --bin e2e_ws
          ./target/debug/e2e_ws
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::e2e_ws_duration_s=${duration_s}"

  deploy:
    name: Deploy To ${{ needs.build.outputs.deploy_env }}
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 20
    needs: [build, deploy_sandbox, e2e-core-local, e2e-core-party, e2e-ws]
    if: |
      needs.build.outputs.deploy_env == 'stg' ||
      (needs.build.outputs.deploy_env == 'dev' && needs.deploy_sandbox.result == 'success')

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Deploy
        id: deploy
        shell: bash
        env:
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
          ARTIFACT_PATH: ${{ needs.build.outputs.artifact_path }}
          BUCKET: ${{ needs.build.outputs.bucket }}
          KEY: ${{ needs.build.outputs.key }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"

          if [[ -n "${BUCKET}" && -n "${KEY}" ]]; then
            ./scripts/cicd/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-s3 "s3://${BUCKET}/${KEY}"
          else
            ./scripts/cicd/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-file "$ARTIFACT_PATH"
          fi
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::deploy_duration_s=${duration_s}"

      - name: Smoke Test
        id: smoke
        shell: bash
        env:
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"

          case "$DEPLOY_ENV" in
            dev) port="4000" ;;
            stg) port="4023" ;;
            *) echo "unknown deploy env: $DEPLOY_ENV" >&2; exit 2 ;;
          esac

          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port "$port"
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::deploy_smoke_duration_s=${duration_s}"

  promote_prod:
    name: Promote To Prod
    runs-on: [self-hosted, Linux, mud]
    timeout-minutes: 30
    needs: [build, deploy]
    if: needs.build.outputs.deploy_env == 'stg'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Copy STG Asset -> prod/
        id: copy
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          aws s3 cp \
            "s3://${BUCKET}/${DEPLOY_ENV}/${SHA}/artifact.tgz" \
            "s3://${BUCKET}/prod/${SHA}/artifact.tgz"
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::promote_copy_duration_s=${duration_s}"

      - name: Store Local Prod Asset (No Rebuild)
        id: sync
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          mkdir -p "assets/prod/${SHA}"
          aws s3 cp "s3://${BUCKET}/prod/${SHA}/artifact.tgz" "assets/prod/${SHA}/artifact.tgz"
          tar -xzf "assets/prod/${SHA}/artifact.tgz" -C "assets/prod/${SHA}" BUILD_INFO.txt 2>/dev/null || true
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::promote_sync_duration_s=${duration_s}"

      - name: Deploy Prod
        id: deploy
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          ./scripts/cicd/slopmud-shuttle-assets \
            --env prd \
            --from-s3 "s3://${BUCKET}/prod/${SHA}/artifact.tgz"
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::promote_deploy_duration_s=${duration_s}"

      - name: Smoke Test (Prod)
        id: smoke
        shell: bash
        run: |
          set -euo pipefail
          start_ts="$(date +%s)"
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4200
          duration_s=$(( $(date +%s) - start_ts ))
          echo "::notice::promote_smoke_duration_s=${duration_s}"

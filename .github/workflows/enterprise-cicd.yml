name: Enterprise CI/CD

on:
  workflow_dispatch:
    inputs:
      track:
        description: "Deployment track"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - stg
      run_sandbox:
        description: "Run sandbox pre-smoke deploy on dev"
        required: false
        default: false
        type: boolean
  push:
    # Intentionally *not* main: avoid accidentally deploying whatever is on main until branches are in place.
    branches:
      - dev
      - stg

permissions:
  contents: read

concurrency:
  group: enterprise-cicd-${{ github.event_name == 'workflow_dispatch' && inputs.track || github.ref_name }}
  cancel-in-progress: true

env:
  AWS_REGION: us-east-1
  AWS_DEFAULT_REGION: us-east-1
  ASSETS_ROOT: assets

jobs:
  build:
    name: Build + Store Asset
    runs-on: [self-hosted, Linux]
    timeout-minutes: 60

    outputs:
      track: ${{ steps.meta.outputs.track }}
      deploy_env: ${{ steps.meta.outputs.deploy_env }}
      sha: ${{ steps.meta.outputs.sha }}
      artifact_path: ${{ steps.meta.outputs.artifact_path }}
      bucket: ${{ steps.s3.outputs.bucket }}
      key: ${{ steps.s3.outputs.key }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # Keep build output/cargo target dirs on the runner for speed.
          clean: false

      - name: Meta
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          sha="${GITHUB_SHA}"
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            track="${{ inputs.track }}"
          else
            track="${GITHUB_REF_NAME}"
          fi

          echo "sha=$sha" >> "$GITHUB_OUTPUT"
          echo "track=$track" >> "$GITHUB_OUTPUT"

          case "$track" in
            dev) deploy_env="dev" ;;
            stg) deploy_env="stg" ;;
            *) echo "unknown track: $track" >&2; exit 2 ;;
          esac
          echo "deploy_env=$deploy_env" >> "$GITHUB_OUTPUT"

      - name: Preflight disk hygiene
        shell: bash
        run: |
          set -euo pipefail
          echo "Disk before cleanup"
          df -h /

          if [[ "${GITHUB_REF_NAME}" == "dev" ]]; then
            echo "Dev branch: keeping workspace and target caches for warm builds."
          else
            avail_kb="$(df -Pk / | awk 'NR==2 {print $4}')"
            if [ "${avail_kb}" -lt 1572864 ]; then
              echo "Disk pressure detected; pruning local target caches to preserve stability."
              rm -rf "$GITHUB_WORKSPACE/target"
              rm -rf /opt/actions-runner/_work/slopmud/slopmud/target
            else
              echo "Keeping local cargo target directories for warm-cache compile speed."
            fi
          fi
          find /opt/actions-runner/_diag -type f -name '*.log' -mtime +7 -delete || true

          avail_kb="$(df -Pk / | awk 'NR==2 {print $4}')"
          if [ "${avail_kb}" -lt 1048576 ]; then
            echo "insufficient free space on / (available ${avail_kb} KB)" >&2
            echo "manual cleanup required on the runner host before retrying" >&2
            exit 2
          fi

          echo "Disk after cleanup"
          df -h /

      - name: Assert Runner Build Deps
        shell: bash
        env:
          DEPLOY_ENV: ${{ steps.meta.outputs.deploy_env }}
          RUN_SANDBOX: ${{ github.event_name == 'workflow_dispatch' && inputs.run_sandbox == true }}
        run: |
          set -euo pipefail
          required_bins=(gcc make pkg-config python3 tar)
          if [[ "$DEPLOY_ENV" == "stg" ]]; then
            required_bins+=(just)
          fi
          for c in "${required_bins[@]}"; do
            command -v "$c" >/dev/null 2>&1 || {
              echo "missing build dependency: $c" >&2
              echo "bootstrap the runner once (as admin on the host) using scripts/cicd/bootstrap_runner.sh" >&2
              exit 2
            }
          done

          # S3 is mandatory for stg and optional for dev when sandbox is requested.
          need_aws=0
          if [[ "$DEPLOY_ENV" == "stg" ]]; then
            need_aws=1
          elif [[ "$DEPLOY_ENV" == "dev" && "$RUN_SANDBOX" == "true" ]]; then
            need_aws=1
          fi
          if [[ "$need_aws" == "1" ]]; then
            command -v aws >/dev/null 2>&1 || {
              echo "missing build dependency: aws (required for S3-backed artifact path)" >&2
              exit 2
            }
          fi

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version
          rustc --version

      - name: Validate (fast + strict)
        shell: bash
        env:
          DEPLOY_ENV: ${{ steps.meta.outputs.deploy_env }}
        run: |
          set -euo pipefail
          if [[ "$DEPLOY_ENV" == "dev" ]]; then
            echo "Dev fast path: skipping validation suite for sub-30s feedback."
          else
            # Hermetic-ish stg validation path: isolated target dir + locked resolution.
            export CARGO_TARGET_DIR="${RUNNER_TEMP}/stg-validate-target"
            rm -rf "${CARGO_TARGET_DIR}"
            cargo fetch --locked
            just fmt-check
            just py-check
            cargo build --workspace --all-targets --locked
            cargo test --locked
            just world-validate
            just proto-lint
          fi

      - name: Build Asset (non-cleanroom)
        id: build_asset
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          # Clean rebuild only on the stg branch/track.
          CLEAN_BUILD: ${{ steps.meta.outputs.deploy_env == 'stg' && '1' || '0' }}
          BUILD_PROFILE: ${{ steps.meta.outputs.deploy_env == 'dev' && 'ci-dev' || 'release' }}
          BUILD_SHARD: ${{ steps.meta.outputs.deploy_env == 'dev' && '0' || '1' }}
        run: |
          set -euo pipefail
          artifact_path="$(./scripts/cicd/build_assets.sh)"
          echo "artifact_path=$artifact_path" >> "$GITHUB_OUTPUT"

      - name: Upload To S3
        id: s3
        if: |
          steps.meta.outputs.deploy_env == 'stg' ||
          (steps.meta.outputs.deploy_env == 'dev' && github.event_name == 'workflow_dispatch' && inputs.run_sandbox == true)
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          SHA: ${{ steps.meta.outputs.sha }}
          ARTIFACT_PATH: ${{ steps.build_asset.outputs.artifact_path }}
        run: |
          set -euo pipefail
          account_id="$(aws sts get-caller-identity --query Account --output text)"
          bucket="slopmud-assets-${account_id}-${AWS_REGION}"
          key="${TRACK}/${SHA}/artifact.tgz"

          set +e
          aws s3 cp "$ARTIFACT_PATH" "s3://${bucket}/${key}"
          rc=$?
          set -e
          if [[ $rc -ne 0 ]]; then
            if [[ "$TRACK" == "dev" ]]; then
              echo "WARN: S3 upload failed (dev track continues without S3). Apply terraform to create/permit the assets bucket." >&2
              bucket=""
              key=""
            else
              exit $rc
            fi
          fi

          echo "bucket=$bucket" >> "$GITHUB_OUTPUT"
          echo "key=$key" >> "$GITHUB_OUTPUT"

      - name: Deploy Dev (inline fast path)
        if: steps.meta.outputs.deploy_env == 'dev'
        shell: bash
        env:
          ARTIFACT_PATH: ${{ steps.build_asset.outputs.artifact_path }}
        run: |
          set -euo pipefail
          shuttle="/usr/local/bin/slopmud-shuttle-assets"
          if [[ ! -x "$shuttle" ]]; then
            shuttle="./scripts/cicd/slopmud-shuttle-assets"
          fi
          sudo "$shuttle" --env dev --from-file "$ARTIFACT_PATH"

      - name: Smoke Test (Dev)
        if: steps.meta.outputs.deploy_env == 'dev'
        shell: bash
        run: |
          set -euo pipefail
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4000

  deploy_sandbox:
    name: Deploy to sandbox (pre-dev smoke)
    runs-on: [self-hosted, Linux]
    timeout-minutes: 20
    needs: build
    if: |
      needs.build.outputs.deploy_env == 'dev' &&
      github.event_name == 'workflow_dispatch' &&
      inputs.run_sandbox == true

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Deploy to sandbox
        shell: bash
        env:
          ARTIFACT_PATH: ${{ needs.build.outputs.artifact_path }}
          BUCKET: ${{ needs.build.outputs.bucket }}
          KEY: ${{ needs.build.outputs.key }}
        run: |
          set -euo pipefail

          if [[ -n "${BUCKET}" && -n "${KEY}" ]]; then
            ./scripts/cicd/slopmud-shuttle-assets \
              --env sandbox \
              --from-s3 "s3://${BUCKET}/${KEY}"
          else
            ./scripts/cicd/slopmud-shuttle-assets \
              --env sandbox \
              --from-file "$ARTIFACT_PATH"
          fi

      - name: Smoke Test
        shell: bash
        run: |
          set -euo pipefail
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4500

  deploy:
    name: Deploy To ${{ needs.build.outputs.deploy_env }}
    runs-on: [self-hosted, Linux]
    timeout-minutes: 20
    needs: build
    if: needs.build.outputs.deploy_env == 'stg'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Deploy
        shell: bash
        env:
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
          ARTIFACT_PATH: ${{ needs.build.outputs.artifact_path }}
          BUCKET: ${{ needs.build.outputs.bucket }}
          KEY: ${{ needs.build.outputs.key }}
        run: |
          set -euo pipefail

          if [[ -n "${BUCKET}" && -n "${KEY}" ]]; then
            ./scripts/cicd/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-s3 "s3://${BUCKET}/${KEY}"
          else
            ./scripts/cicd/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-file "$ARTIFACT_PATH"
          fi

      - name: Smoke Test
        shell: bash
        run: |
          set -euo pipefail
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4023

  promote_prod:
    name: Promote To Prod
    runs-on: [self-hosted, Linux]
    timeout-minutes: 30
    needs: [build, deploy]
    if: needs.build.outputs.deploy_env == 'stg'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Sync local shuttle helper
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/cicd/slopmud-shuttle-assets

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Copy STG Asset -> prod/
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
        run: |
          set -euo pipefail
          aws s3 cp \
            "s3://${BUCKET}/${DEPLOY_ENV}/${SHA}/artifact.tgz" \
            "s3://${BUCKET}/prod/${SHA}/artifact.tgz"

      - name: Store Local Prod Asset (No Rebuild)
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          mkdir -p "assets/prod/${SHA}"
          aws s3 cp "s3://${BUCKET}/prod/${SHA}/artifact.tgz" "assets/prod/${SHA}/artifact.tgz"
          tar -xzf "assets/prod/${SHA}/artifact.tgz" -C "assets/prod/${SHA}" BUILD_INFO.txt 2>/dev/null || true

      - name: Deploy Prod
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          ./scripts/cicd/slopmud-shuttle-assets \
            --env prd \
            --from-s3 "s3://${BUCKET}/prod/${SHA}/artifact.tgz"

      - name: Smoke Test (Prod)
        shell: bash
        run: |
          set -euo pipefail
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4200

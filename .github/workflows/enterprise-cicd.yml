name: Enterprise CI/CD

on:
  workflow_dispatch:
    inputs:
      track:
        description: "Deployment track"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - stg
  push:
    # Intentionally *not* main: avoid accidentally deploying whatever is on main until branches are in place.
    branches:
      - dev
      - stg

permissions:
  contents: read

concurrency:
  group: enterprise-cicd-${{ github.event_name == 'workflow_dispatch' && inputs.track || github.ref_name }}
  cancel-in-progress: true

env:
  AWS_REGION: us-east-1
  AWS_DEFAULT_REGION: us-east-1
  ASSETS_ROOT: assets

jobs:
  build:
    name: Build + Store Asset
    runs-on: [self-hosted, Linux]
    timeout-minutes: 60

    outputs:
      track: ${{ steps.meta.outputs.track }}
      deploy_env: ${{ steps.meta.outputs.deploy_env }}
      sha: ${{ steps.meta.outputs.sha }}
      artifact_path: ${{ steps.meta.outputs.artifact_path }}
      bucket: ${{ steps.s3.outputs.bucket }}
      key: ${{ steps.s3.outputs.key }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # Keep build output/cargo target dirs on the runner for speed.
          clean: false

      - name: Meta
        id: meta
        shell: bash
        run: |
          set -euo pipefail

          sha="${GITHUB_SHA}"
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            track="${{ inputs.track }}"
          else
            track="${GITHUB_REF_NAME}"
          fi

          echo "sha=$sha" >> "$GITHUB_OUTPUT"
          echo "track=$track" >> "$GITHUB_OUTPUT"

          case "$track" in
            dev) deploy_env="dev" ;;
            stg) deploy_env="stg" ;;
            *) echo "unknown track: $track" >&2; exit 2 ;;
          esac
          echo "deploy_env=$deploy_env" >> "$GITHUB_OUTPUT"

      - name: Preflight disk hygiene
        shell: bash
        run: |
          set -euo pipefail
          echo "Disk before cleanup"
          df -h /

          rm -rf "$GITHUB_WORKSPACE/target"
          rm -rf /opt/actions-runner/_work/slopmud/slopmud/target
          find /opt/actions-runner/_diag -type f -name '*.log' -mtime +7 -delete || true

          avail_kb="$(df -Pk / | awk 'NR==2 {print $4}')"
          if [ "${avail_kb}" -lt 1048576 ]; then
            echo "insufficient free space on / (available ${avail_kb} KB)" >&2
            echo "manual cleanup required on the runner host before retrying" >&2
            exit 2
          fi

          echo "Disk after cleanup"
          df -h /

      - name: Assert Runner Build Deps
        shell: bash
        run: |
          set -euo pipefail
          for c in gcc make pkg-config just python3 tar; do
            command -v "$c" >/dev/null 2>&1 || {
              echo "missing build dependency: $c" >&2
              echo "bootstrap the runner once (as admin on the host) using scripts/cicd/bootstrap_runner.sh" >&2
              exit 2
            }
          done

          # Only required for the S3 artifact path; dev track can fall back to local artifacts.
          command -v aws >/dev/null 2>&1 || {
            echo "WARN: aws CLI is missing; S3 upload will fail (dev continues, stg/prod requires aws)" >&2
          }

      - name: Rust Toolchain On PATH
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "$HOME/.cargo/env" ]]; then
            # shellcheck disable=SC1090
            source "$HOME/.cargo/env"
          else
            export PATH="$HOME/.cargo/bin:$PATH"
          fi
          echo "$HOME/.cargo/bin" >> "$GITHUB_PATH"
          cargo --version
          rustc --version

      - name: Validate (fast + strict)
        shell: bash
        env:
          RUSTFLAGS: "-D warnings"
          DEPLOY_ENV: ${{ steps.meta.outputs.deploy_env }}
        run: |
          set -euo pipefail
          just fmt-check
          just py-check

          # dev: keep this fast for iteration; stg: run the full validation suite.
          if [[ "$DEPLOY_ENV" == "dev" ]]; then
            cargo build -q --workspace --all-targets
            cargo test -q -p slopmud
          else
            cargo build -q --workspace --all-targets
            cargo test -q
            just world-validate
            just proto-lint
          fi

      - name: Build Asset (non-cleanroom)
        id: build_asset
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          # Clean rebuild only on the stg branch/track.
          CLEAN_BUILD: ${{ steps.meta.outputs.deploy_env == 'stg' && '1' || '0' }}
        run: |
          set -euo pipefail
          artifact_path="$(./scripts/cicd/build_assets.sh)"
          echo "artifact_path=$artifact_path" >> "$GITHUB_OUTPUT"

      - name: Upload To S3
        id: s3
        shell: bash
        env:
          TRACK: ${{ steps.meta.outputs.deploy_env }}
          SHA: ${{ steps.meta.outputs.sha }}
          ARTIFACT_PATH: ${{ steps.build_asset.outputs.artifact_path }}
        run: |
          set -euo pipefail
          account_id="$(aws sts get-caller-identity --query Account --output text)"
          bucket="slopmud-assets-${account_id}-${AWS_REGION}"
          key="${TRACK}/${SHA}/artifact.tgz"

          set +e
          aws s3 cp "$ARTIFACT_PATH" "s3://${bucket}/${key}"
          rc=$?
          set -e
          if [[ $rc -ne 0 ]]; then
            if [[ "$TRACK" == "dev" ]]; then
              echo "WARN: S3 upload failed (dev track continues without S3). Apply terraform to create/permit the assets bucket." >&2
              bucket=""
              key=""
            else
              exit $rc
            fi
          fi

          echo "bucket=$bucket" >> "$GITHUB_OUTPUT"
          echo "key=$key" >> "$GITHUB_OUTPUT"

  deploy:
    name: Deploy To ${{ needs.build.outputs.deploy_env }}
    runs-on: [self-hosted, Linux]
    timeout-minutes: 20
    needs: build
    if: needs.build.outputs.deploy_env == 'dev' || needs.build.outputs.deploy_env == 'stg'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          sudo -n /usr/local/bin/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Deploy
        shell: bash
        env:
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
          ARTIFACT_PATH: ${{ needs.build.outputs.artifact_path }}
          BUCKET: ${{ needs.build.outputs.bucket }}
          KEY: ${{ needs.build.outputs.key }}
        run: |
          set -euo pipefail

          if [[ -n "${BUCKET}" && -n "${KEY}" ]]; then
            sudo -n /usr/local/bin/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-s3 "s3://${BUCKET}/${KEY}"
          else
            sudo -n /usr/local/bin/slopmud-shuttle-assets \
              --env "$DEPLOY_ENV" \
              --from-file "$ARTIFACT_PATH"
          fi

      - name: Smoke Test
        shell: bash
        env:
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
        run: |
          set -euo pipefail

          case "$DEPLOY_ENV" in
            dev) port="4000" ;;
            stg) port="4023" ;;
            *) echo "unknown deploy env: $DEPLOY_ENV" >&2; exit 2 ;;
          esac

          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port "$port"

  promote_prod:
    name: Promote To Prod
    runs-on: [self-hosted, Linux]
    timeout-minutes: 30
    needs: [build, deploy]
    if: needs.build.outputs.deploy_env == 'stg'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Assert Deploy Hook Installed
        shell: bash
        run: |
          set -euo pipefail
          sudo -n /usr/local/bin/slopmud-shuttle-assets --help >/dev/null 2>&1

      - name: Copy STG Asset -> prod/
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
          DEPLOY_ENV: ${{ needs.build.outputs.deploy_env }}
        run: |
          set -euo pipefail
          aws s3 cp \
            "s3://${BUCKET}/${DEPLOY_ENV}/${SHA}/artifact.tgz" \
            "s3://${BUCKET}/prod/${SHA}/artifact.tgz"

      - name: Store Local Prod Asset (No Rebuild)
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          mkdir -p "assets/prod/${SHA}"
          aws s3 cp "s3://${BUCKET}/prod/${SHA}/artifact.tgz" "assets/prod/${SHA}/artifact.tgz"
          tar -xzf "assets/prod/${SHA}/artifact.tgz" -C "assets/prod/${SHA}" BUILD_INFO.txt 2>/dev/null || true

      - name: Deploy Prod
        shell: bash
        env:
          BUCKET: ${{ needs.build.outputs.bucket }}
          SHA: ${{ needs.build.outputs.sha }}
        run: |
          set -euo pipefail
          sudo -n /usr/local/bin/slopmud-shuttle-assets \
            --env prd \
            --from-s3 "s3://${BUCKET}/prod/${SHA}/artifact.tgz"

      - name: Smoke Test (Prod)
        shell: bash
        run: |
          set -euo pipefail
          python3 ./scripts/cicd/smoke_telnet.py --host 127.0.0.1 --port 4200
